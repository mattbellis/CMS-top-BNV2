{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baece871-9e09-4368-9709-ff7bc392c621",
   "metadata": {},
   "source": [
    "# Install or upgrade libraries\n",
    "\n",
    "It might be that you are running with the latest libraries and that they all work together fine. \n",
    "\n",
    "Running the following cell takes a minute or so but ensures that you have a consistent set of python tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c37f5-ee33-49c8-b7f9-f95aba7c2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install futures \n",
    "!pip install --upgrade awkward\n",
    "!pip install --upgrade uproot\n",
    "\n",
    "!pip install fsspec-xrootd\n",
    "\n",
    "!pip install vector\n",
    "\n",
    "!pip install --upgrade pandas\n",
    "\n",
    "\n",
    "!pip install --upgrade matplotlib\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863baff-92dd-4a06-87e4-9fcaf371d6ed",
   "metadata": {},
   "source": [
    "We've also prepared some helper code that makes it easier to work with the data in this lesson.\n",
    "\n",
    "You can see the code [here](https://github.com/cms-opendata-workshop/workshop2024-lesson-event-selection/blob/main/instructors/dpoa_workshop_utilities.py) but we will explain the functions and data objects in this notebook. \n",
    "\n",
    "Let's download it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a8170-8a5f-4248-bbc4-e1b650391d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/cms-opendata-workshop/workshop2024-lesson-event-selection/main/instructors/dpoa_workshop_utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbef50-6ee3-4b6e-8b8e-97a24c2ee234",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all the libraries we will need and check their versions, in case you run into issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f5d17-46bf-45eb-a8fe-58f85d170c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# The classics\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib # To get the version\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# The newcomers\n",
    "import awkward as ak\n",
    "import uproot\n",
    "\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "import dpoa_workshop_utilities\n",
    "from dpoa_workshop_utilities import nanoaod_filenames\n",
    "from dpoa_workshop_utilities import get_files_for_dataset\n",
    "from dpoa_workshop_utilities import pretty_print\n",
    "from dpoa_workshop_utilities import build_lumi_mask\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4186f-3d22-417e-a66c-2d869bbfb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Versions --------\\n\")\n",
    "print(f\"{sys.version = }\\n\")\n",
    "print(f\"{ak.__version__ = }\\n\")\n",
    "print(f\"{uproot.__version__ = }\\n\")\n",
    "print(f\"{np.__version__ = }\\n\")\n",
    "print(f\"{matplotlib.__version__ = }\\n\")\n",
    "print(f\"{vector.__version__ = }\\n\")\n",
    "print(f\"{pd.__version__ = }\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f47a5-0fbb-444a-b6a8-c44b2ce9ff5f",
   "metadata": {},
   "source": [
    "## Datasets and files\n",
    "\n",
    "### Download the essential files\n",
    "\n",
    "Eventually, we will want to process all the that are in some datasets. And for now, we would like to try to ensure\n",
    "that not every one of you is accessing the same file at the same time. \n",
    "\n",
    "We've prepared some utilities in a files called `dpoa_workshop_utilities` that will make some of your work in this lesson easier. \n",
    "\n",
    "In an [earlier lesson](https://cms-opendata-workshop.github.io/workshop2024-lesson-dataset-scouting/instructor/index.html), you learned that the Open Data Portal provides files that list all of the ROOT files that are part of that dataset. \n",
    "\n",
    "We've provided those files as a dictionary called `nanoaod_filenames`. It's a python dictionary, that has the different datsets, as keys. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5a3e9-73ad-45f7-b87d-4f7124e1ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nanoaod_filenames.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d36c8-e658-45ab-bde8-ceaa9c642829",
   "metadata": {},
   "source": [
    "`collision` refers to the data and the other names refer to the signal MC and background MC samples. \n",
    "\n",
    "* Signal MC datasets\n",
    "  * `signal_M2000`\n",
    "* Background MC datasets\n",
    "  * `ttsemilep`\n",
    "  * `tthadronic`\n",
    "  * `ttleptonic`\n",
    "  * `Wjets`\n",
    "  \n",
    "We can look at the file names of one of these datasets. Remember, these are the files *that contain the names and locations* of the actual ROOT files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0969cb66-59a1-4976-9cfb-dcdc00354ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanoaod_filenames['ttsemilep']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6588aa-3f4b-40c2-b788-b043e5de879a",
   "metadata": {},
   "source": [
    "We're going to download the contents of files (not the ROOT files!) to your docker space, so that you can run over subsets of these datasets. \n",
    "\n",
    "We merge the output into files with names like `FILE_LIST_ttsemilep.txt` for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb1322-4400-4ce4-b210-d842deadf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download these files\n",
    "\n",
    "for datasetname in nanoaod_filenames.keys():\n",
    "    \n",
    "    print(datasetname)\n",
    "\n",
    "    outfilename = f'FILE_LIST_{datasetname}.txt'\n",
    "\n",
    "    # Remove the file if it exists\n",
    "    try:\n",
    "        os.remove(outfilename)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for url in nanoaod_filenames[datasetname]:\n",
    "        print(url)\n",
    "\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "        open(outfilename, 'a').write(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292aa6b-33c2-4e78-ac9a-ad9e70ee7737",
   "metadata": {},
   "source": [
    "We can execute some Linux commands to see what is inside them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04e51c-7e07-439e-8afe-f1f1cdd2d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7506d9-5c7d-4817-89ce-f44eaac96ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the last 5 lines of one of these files. \n",
    "!tail -5 FILE_LIST_ttsemilep.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f39c0-5c7e-4472-a6cc-151a93768b32",
   "metadata": {},
   "source": [
    "### **Challenge!**\n",
    "\n",
    "You can get the number of files by counting the lines in each of your combined data files. You can do this\n",
    "by running the command\n",
    "\n",
    "```\n",
    "!wc -l FILE_LIST_*.txt\n",
    "```\n",
    "\n",
    "Run this command in the cell below. How many collision files are there? How many signal files are there? How many files are there combined in the background sample files? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba671eb1-af3c-4d4b-a579-8dc2bed8d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "!wc -l FILE_LIST_*.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f4163-1883-421e-9a72-cb2562fdcd13",
   "metadata": {},
   "source": [
    "We also need the file that tells us what runs and events we have good luminosity calculations for, so let's get that now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf7ea4-c7da-4399-b304-b5c07481afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the lumi file\n",
    "!wget https://opendata.cern.ch/record/14220/files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41e75b-d30d-4888-a3cd-6d76947b913d",
   "metadata": {},
   "source": [
    "We've also provided you with a helper function to get the names of one of these ROOT files from the dictionary, \n",
    "either all of them or a subset that we pick randomly. \n",
    "\n",
    "This is going to allow most of us to access different files. Hopefully this works! :)\n",
    "\n",
    "We'll try this for the `ttsemilep` since there are many files in the list so there is a better chance that most people will access a different file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe99a36-6961-4119-9c29-4aa522bcede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = get_files_for_dataset(\"ttsemilep\", random=True, n=1)\n",
    "\n",
    "filename = filenames[0]\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e79755-6dac-485e-83f5-a11f4f40892e",
   "metadata": {},
   "source": [
    "Did we mostly get different files? Cut and paste the last set of numbers and letters from the filename into the chat. \n",
    "\n",
    "Now we're ready to work with these files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b2eb48-ca50-471d-ac2e-d4b804bb674b",
   "metadata": {},
   "source": [
    "## Selecting the data\n",
    "\n",
    "### Can you open the datafile?\n",
    "\n",
    "We'll work with the random `ttsemilep` file you already selected in the previous cells. We'll make use of `uproot` to open the file and \n",
    "pull out the number of events. \n",
    "\n",
    "Depending on your connection anw which random file you open, it may take 10-30 seconds for the cell to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51207f39-0530-43dc-92b6-e3a2ffb615ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filenames[0]\n",
    "print(f\"Opening...{filename}\")\n",
    "f = uproot.open(filename)\n",
    "\n",
    "events = f['Events']\n",
    "\n",
    "nevents = events.num_entries\n",
    "\n",
    "print(f\"{nevents = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4004055-8e11-432e-af2d-3ad74c058238",
   "metadata": {},
   "source": [
    "The `events` object is a `TTree` implementation in python and behaves like a dictionary. This means \n",
    "we can get all the keys if we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d2003-950d-4aa2-be40-e896d3f4e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to print all the keys\n",
    "\n",
    "#print(events.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fae75-f126-4916-8261-bbaccf54af3f",
   "metadata": {},
   "source": [
    "Again, we have provided you with a helper function called `pretty_print` that will print subsets of the keys, based on strings\n",
    "that you require or ignore. \n",
    "\n",
    "It will also format that output based on how many characters you want in a column (you are limited to 80 characters per line). \n",
    "\n",
    "Here is some example usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca48d59-6470-4298-8ce4-e77bbfb332df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print all the keys with the default format\n",
    "#pretty_print(events.keys())\n",
    "\n",
    "# Pretty print keys with 30 characters per column, for keys that contain `FatJet`\n",
    "#pretty_print(events.keys(), fmt='30s', require='FatJet')\n",
    "\n",
    "# Pretty print keys with 40 characters per column, for keys that contain `Muon` and `Iso` but ignore ones with `HLT`\n",
    "pretty_print(events.keys(), fmt='40s', require=['Muon', 'Iso'], ignore='HLT')\n",
    "\n",
    "# Pretty print keys with 40 characters per column, for keys that contain `HLT` and `TkMu50`\n",
    "#pretty_print(events.keys(), fmt='40s', require=['HLT', 'TkMu50'])\n",
    "\n",
    "# Pretty print keys with 40 characters per column, for keys that contain `HLT`\n",
    "#pretty_print(events.keys(), fmt='40s', require='HLT')\n",
    "\n",
    "# Pretty print keys with 40 characters per column, for keys that contain `Jet_` but ignore ones with `Fat`\n",
    "#pretty_print(events.keys(), fmt='40s', require='Jet_', ignore='Fat')\n",
    "\n",
    "# Pretty print keys with 40 characters per column, for keys that contain `PuppiMET` but ignore ones with `Raw`\n",
    "#pretty_print(events.keys(), fmt='40s', require='PuppiMET', ignore='Raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c9534-03d2-4729-9172-b9f36e18e4bd",
   "metadata": {},
   "source": [
    "## Extract some data\n",
    "\n",
    "We're going to pull out subsets of the data in order to do our analysis. \n",
    "\n",
    "As a reminder, you can find a list of the variable names in each dataset on the CERN Open Data Portal page for that dataset, for example, [here](https://opendata.cern.ch/eos/opendata/cms/dataset-semantics/NanoAODSIM/75156/ZprimeToTT_M2000_W20_TuneCP2_PSweights_13TeV-madgraph-pythiaMLM-pythia8_doc.html).\n",
    "\n",
    "We're going to work with the following sets of variables\n",
    "* `FatJet` for jets that are merges\n",
    "* `Jet` for non-merged jets\n",
    "* `Muon` for muons\n",
    "* `PuppiMET` which is missing energy in the transverse plane (MET) for pileup per particle identification (Puppi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8202845-019a-4133-ba4c-a6dc966c3298",
   "metadata": {},
   "source": [
    "# My new stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a368bdf-5802-49e5-a7c1-0bbbb83d1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jets ---------------------------------------------------\n",
    "# B-tagging variable\n",
    "jet_btag = events['Jet_btagDeepB'].array()\n",
    "\n",
    "# Measure of quality of measurement of jet\n",
    "jet_jetid = events['Jet_jetId'].array()\n",
    "\n",
    "# 4-momentum in pt, eta, phi, mass \n",
    "jet_pt = events['Jet_pt'].array()\n",
    "jet_eta = events['Jet_eta'].array()\n",
    "jet_phi = events['Jet_phi'].array()\n",
    "jet_mass = events['Jet_mass'].array()\n",
    "\n",
    "\n",
    "# Muons ---------------------------------------------------\n",
    "# Muon isolation\n",
    "muon_iso = events['Muon_miniIsoId'].array()\n",
    "\n",
    "# Measure of quality of how well the muon is reconstructed\n",
    "muon_tightId = events['Muon_tightId'].array()\n",
    "\n",
    "# 4-momentum in pt, eta, phi, mass \n",
    "muon_pt = events['Muon_pt'].array()\n",
    "muon_eta = events['Muon_eta'].array()\n",
    "muon_phi = events['Muon_phi'].array()\n",
    "muon_mass = events['Muon_mass'].array()\n",
    "\n",
    "\n",
    "# MET ------------------------------------------------------\n",
    "# 3-momentum in pt, eta, phi, mass \n",
    "met_pt = events['PuppiMET_pt'].array()\n",
    "met_eta = 0*events['PuppiMET_pt'].array()  # Fix this to be 0\n",
    "met_phi = events['PuppiMET_phi'].array() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874fcb9-040c-430b-b94a-b34f03834149",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(ak.flatten(jet_pt),bins=100,range=(0,250));\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(ak.flatten(jet_pt),bins=100,range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac9f47-7453-4b42-833f-ba50d7355bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_jet_pt = jet_pt>20\n",
    "\n",
    "njets = ak.num(jet_pt)\n",
    "njets_after_cut = ak.num(jet_pt[cut_jet_pt])\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(njets,          bins=20, range=(0,20))\n",
    "plt.locator_params(axis='x', nbins=20)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(njets_after_cut,bins=20, range=(0,20))\n",
    "plt.locator_params(axis='x', nbins=20)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90370a4-6a24-42bb-abf0-e94144c7b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#njet_cut = ak.num(jet_pt[cut_jet_pt], axis=1) >= 6\n",
    "njet_cut = ak.num(jet_pt[cut_jet_pt], axis=1) == 6\n",
    "\n",
    "njet_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cbb1f-948c-4f58-9315-5fd312c592fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nevents_pass_njet_cut = ak.num(njet_cut[njet_cut], axis=0)\n",
    "nevents_pass_njet_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093a871-094b-4bdf-bb3d-8a771d07d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_muon = (muon_pt>25) & (muon_eta>-2.4) & (muon_eta<2.4) & \\\n",
    "           (muon_tightId == True) & (muon_iso>1)\n",
    "\n",
    "# MET ------------------------------------------------------\n",
    "# 3-momentum in pt, eta, phi, mass \n",
    "met_pt = events['PuppiMET_pt'].array()\n",
    "met_eta = 0*events['PuppiMET_pt'].array()  # Fix this to be 0\n",
    "met_phi = events['PuppiMET_phi'].array() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b4d0a-0fef-4f41-b4a4-e33aca8212e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_event = njet_cut\n",
    "\n",
    "cut_jet = cut_jet_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923d492-ee89-46e4-8104-4400d19a24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jets = ak.zip(\n",
    "    {\"pt\": jet_pt[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"eta\": jet_eta[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"phi\": jet_phi[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"mass\": jet_mass[cut_full_event][cut_jet[cut_full_event]]},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "\n",
    "#'''\n",
    "muons = ak.zip(\n",
    "    {\"pt\": muon_pt[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"eta\": muon_eta[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"phi\": muon_phi[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"mass\": muon_mass[cut_full_event][cut_muon[cut_full_event]]},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "\n",
    "met = ak.zip(\n",
    "    {\"pt\": met_pt[cut_full_event], \n",
    "     \"eta\": met_eta[cut_full_event], \n",
    "     \"phi\": met_phi[cut_full_event], \n",
    "     \"mass\": 0}, # We assume this is a neutrino with 0 mass\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685cfd14-98bb-445f-a872-b740d5182e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4jets = ak.combinations(jets, 6)\n",
    "\n",
    "p4j1, p4j2, p4j3, p4j4, p4j5, p4j6 = ak.unzip(p4jets)\n",
    "\n",
    "#p4mu,p4fj,p4j,p4met = ak.unzip(ak.cartesian([muons, fatjets, jets, met]))\n",
    "#p4j1, p4j2, p4j3, p4j4, p4j5, p4j6, p4mu, p4met = ak.unzip(ak.cartesian([p4jets, muons, met]))\n",
    "p4j1, p4j2, p4j3, p4j4, p4j5, p4j6, p4mu, p4met = ak.unzip(ak.cartesian([p4j1, p4j2, p4j3, p4j4, p4j5, p4j6, muons, met]))\n",
    "\n",
    "\n",
    "#p4mu = ak.combinations(muons,1)\n",
    "\n",
    "#p4mmet = ak.combinations(met,1)\n",
    "\n",
    "\n",
    "# Calculate a sum of the 4-momenta\n",
    "#p4tot = p4mu + p4fj + p4j + p4met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570dc2ee-00ee-445b-b5ae-2471f4f5048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4jets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab5cb2-89d9-4344-bf80-fd1a52d95cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p4j1[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54a9f4-a2b8-4f19-bb5e-65c10e4f3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p4j1, p4j2, p4j3, p4j4, p4j5, p4j6 = ak.unzip(p4jets)\n",
    "#p4j2.mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0162614-af53-4f0f-9a03-0366a730f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4tot = p4j1 + p4j2 + p4j3 + p4j4 + p4j5\n",
    "\n",
    "p4tot2 = p4j6 + p4mu + met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e645557-e4b4-4d8a-b828-b239b8b634b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ak.num(p4tot.mass))\n",
    "print(ak.num(p4tot2.mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c4235-6a70-41a2-8ce2-7f73f9b3cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ak.flatten(p4tot.mass)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(m, bins=300, range=(0,3000));\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(m, bins=50, range=(0,500));\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(m, bins=25, range=(100,250));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d57a2-f1a9-4e6c-945c-31f74e5cc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ak.flatten(p4tot2.mass)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(m, bins=300, range=(0,3000));\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(m, bins=50, range=(0,500));\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(m, bins=25, range=(100,250));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e728f74-9cb2-4b18-8bc5-ebb31f97b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4tot = p4j1 + p4j2 + p4j3 + p4j4 + p4j5\n",
    "masses1 = ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot = p4j1 + p4j2 + p4j3 + p4j4 + p4j6\n",
    "masses1 += ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot = p4j1 + p4j2 + p4j3 + p4j5 + p4j6\n",
    "masses1 += ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot = p4j1 + p4j2 + p4j4 + p4j5 + p4j6\n",
    "masses1 += ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot = p4j1 + p4j3 + p4j4 + p4j5 + p4j6\n",
    "masses1 += ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot = p4j2 + p4j3 + p4j4 + p4j5 + p4j6\n",
    "masses1 += ak.flatten(p4tot.mass).to_numpy().tolist()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(masses1, bins=300, range=(0,3000));\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(masses1, bins=50, range=(0,500));\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(masses1, bins=25, range=(100,250));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b171f-a83e-4703-bc67-629bb503f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4tot2 = p4j6 + p4mu + met\n",
    "masses2 = ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot2 = p4j5 + p4mu + met\n",
    "masses2 += ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot2 = p4j4 + p4mu + met\n",
    "masses2 += ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot2 = p4j3 + p4mu + met\n",
    "masses2 += ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot2 = p4j2 + p4mu + met\n",
    "masses2 += ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "p4tot2 = p4j1 + p4mu + met\n",
    "masses2 += ak.flatten(p4tot2.mass).to_numpy().tolist()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(masses2, bins=300, range=(0,3000));\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(masses2, bins=50, range=(0,500));\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(masses2, bins=25, range=(100,250));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6a65d-e018-4274-a9bf-85acb8a40eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f41ab-10c0-48ac-bc78-9b4f22811b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f497e5-b001-4982-b3f4-8ea462992840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840fdb7-fd84-4cac-b170-b41e0610ad65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9dbc8-a57b-455b-bdc4-7f8e5ab75f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc733a-316f-45e1-ad49-132e1ba86f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96697dd6-ef53-4e33-962e-e3e03ae185fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fat jets ---------------------------------------------------\n",
    "\n",
    "# Soft-drop mass, calculated using a particular algorithm\n",
    "fatjet_mSD = events['FatJet_msoftdrop'].array()\n",
    "\n",
    "# A newer tagging algorithm to identify merged top-quark jets\n",
    "fatjet_tag = events['FatJet_particleNet_TvsQCD'].array()\n",
    "\n",
    "# Measures of subjettiness, used in the original analysis\n",
    "fatjet_tau2 = events['FatJet_tau2'].array()\n",
    "fatjet_tau3 = events['FatJet_tau3'].array()\n",
    "\n",
    "# 4-momentum in pt, eta, phi, mass \n",
    "fatjet_pt = events['FatJet_pt'].array()\n",
    "fatjet_eta = events['FatJet_eta'].array()\n",
    "fatjet_phi = events['FatJet_phi'].array()\n",
    "fatjet_mass = events['FatJet_mass'].array()\n",
    "\n",
    "\n",
    "# Jets ---------------------------------------------------\n",
    "# B-tagging variable\n",
    "jet_btag = events['Jet_btagDeepB'].array()\n",
    "\n",
    "# Measure of quality of measurement of jet\n",
    "jet_jetid = events['Jet_jetId'].array()\n",
    "\n",
    "# 4-momentum in pt, eta, phi, mass \n",
    "jet_pt = events['Jet_pt'].array()\n",
    "jet_eta = events['Jet_eta'].array()\n",
    "jet_phi = events['Jet_phi'].array()\n",
    "jet_mass = events['Jet_mass'].array()\n",
    "\n",
    "\n",
    "# Muons ---------------------------------------------------\n",
    "# Muon isolation\n",
    "muon_iso = events['Muon_miniIsoId'].array()\n",
    "\n",
    "# Measure of quality of how well the muon is reconstructed\n",
    "muon_tightId = events['Muon_tightId'].array()\n",
    "\n",
    "# 4-momentum in pt, eta, phi, mass \n",
    "muon_pt = events['Muon_pt'].array()\n",
    "muon_eta = events['Muon_eta'].array()\n",
    "muon_phi = events['Muon_phi'].array()\n",
    "muon_mass = events['Muon_mass'].array()\n",
    "\n",
    "\n",
    "# MET ------------------------------------------------------\n",
    "# 3-momentum in pt, eta, phi, mass \n",
    "met_pt = events['PuppiMET_pt'].array()\n",
    "met_eta = 0*events['PuppiMET_pt'].array()  # Fix this to be 0\n",
    "met_phi = events['PuppiMET_phi'].array() \n",
    "\n",
    "# Scalar quantity used in selection criteria\n",
    "ht_lep = muon_pt + met_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94999f9-c6dd-42d4-afde-494041380682",
   "metadata": {},
   "source": [
    "## Selections\n",
    "\n",
    "We are going to create a series of masks that will return only subsets of the data that pass certain criteria. \n",
    "\n",
    "We will distinguish between cuts that select *events* and cuts that select *particles*. \n",
    "\n",
    "For example, a cut that selects *event* might only select events with MET greater than a certain value, since there is only one MET for any event, or events that are recorded on a Friday. \n",
    "\n",
    "A cut that selects certain particles might select muons with some $p_T$ greater than a certain value or jets that are tagged as coming from $b$-quark hadronization. \n",
    "\n",
    "When we apply our *particle* cuts, we actually have to select only the cuts that also pass the *event* cuts! It can be confusing, so let's start with a simple example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0d7c9-fe06-458e-b36b-bf8afd6adbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mock Awkward array of 3 events where we record MET and the muon pT.\n",
    "\n",
    "# There are 3 muons in the first event, 1 muon in the second event and 4 muons in the 3rd event\n",
    "\n",
    "arr = ak.Array({'MET':[80,20,54], 'muon_pt': [[110, 90, 10], [40], [250, 25, 10, 5]]})\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e859a-d603-4444-94d2-b394d910a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select events with MET > 25 and muon pT > 30\n",
    "\n",
    "event_cut = arr['MET'] > 25\n",
    "\n",
    "muon_cut = arr['muon_pt'] > 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd8f3d-393a-4a21-96d6-9789f74d5602",
   "metadata": {},
   "source": [
    "But what are these python objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543be06c-099e-4e38-b9df-22d94fc05eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_cut)\n",
    "print()\n",
    "\n",
    "print(muon_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847896e6-5806-4a37-bcd2-59ef67ff3b16",
   "metadata": {},
   "source": [
    "They are just arrays of `True` and `False` that correspond to either the event or the particle passing\n",
    "that particular cut. \n",
    "\n",
    "Note that they have very different shapes. \n",
    "\n",
    "`event_cut` has 3 entries corresponding to our 3 events. \n",
    "\n",
    "`muon_cut` has the same shape as the `muon_pt` array because there is a `True`/`False` for each muon.\n",
    "\n",
    "We can now pass these back into our original data array to put out subsets of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a56fed-fb5b-42f5-acb0-3f28b468736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we use the muon cut, we actually have to pick out subsets that pass the event cut\n",
    "# So the order of this approach is\n",
    "# arr[event_cut] - select events that pass the event cut\n",
    "# arr[event_cut]['muon_pt'] - pull out the muon_pt values\n",
    "# arr[event_cut]['muon_pt'][muon_cut[event_cut]] - select values that pass the muon cut,\n",
    "#                                                  but make sure the muon cut is selected for \n",
    "#                                                  the surviving events\n",
    "\n",
    "pt = arr[event_cut]['muon_pt'][muon_cut[event_cut]]\n",
    "\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e42a9-faee-4129-8a68-e5b587a928ef",
   "metadata": {},
   "source": [
    "It may help you to play around with the above and print out the different steps. \n",
    "\n",
    "Now lets make the selections for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cc8e7-8e54-4cb2-a9b6-3c45fe381383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle-specific cuts -------------------------------------------\n",
    "\n",
    "# Fat jet cuts --------------------------------\n",
    "# Calculate a ratio of subjettiness variables\n",
    "tau32 = fatjet_tau3/fatjet_tau2\n",
    "\n",
    "# This is what was used in the old analysis\n",
    "#cut_fatjet = (tau32>0.67) & (fatjet_eta>-2.4) & (fatjet_eta<2.4) & (fatjet_mSD>105) & (fatjet_mSD<220)\n",
    "\n",
    "# We simplified it for this less\n",
    "cut_fatjet = (fatjet_pt > 500) & (fatjet_tag > 0.5)\n",
    "\n",
    "# Muon cuts ----------------------------------\n",
    "cut_muon = (muon_pt>55) & (muon_eta>-2.4) & (muon_eta<2.4) & \\\n",
    "           (muon_tightId == True) & (muon_iso>1) & (ht_lep>150)\n",
    "\n",
    "# Non-boosted jet cuts ------------------------\n",
    "cut_jet = (jet_btag > 0.5) & (jet_jetid>=4)\n",
    "\n",
    "\n",
    "\n",
    "# Event cuts --------------------------------------------------------\n",
    "# MET cuts --------------------\n",
    "cut_met = (met_pt > 50)\n",
    "\n",
    "# Cuts on number of muons that pass our cuts\n",
    "cut_nmuons = ak.num(cut_muon[cut_muon]) == 1\n",
    "\n",
    "# Cut on the event passing the trigger \n",
    "cut_trigger = (events['HLT_TkMu50'].array())\n",
    "\n",
    "# Cut on the number of fat jets that pass our selection criteria\n",
    "cut_ntop = ak.num(cut_fatjet[cut_fatjet]) == 1\n",
    "\n",
    "# Create a cut for the full event that is the \"and\" of all the separate cuts\n",
    "cut_full_event = cut_trigger & cut_nmuons & cut_met & cut_ntop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bde83e-9c1a-4012-8b03-0cedaa8565ec",
   "metadata": {},
   "source": [
    "## Use the cuts and calculate some values\n",
    "\n",
    "We can use the [Vector class](https://vector.readthedocs.io/en/latest/)\n",
    "to help us with our 4-vector arithmetic. \n",
    "\n",
    "We create 4-vector objects for the fat jets, jets, muons, and MET. These can be used with the Awkward array class to naturally handle combinations of particles within a given event, for example, calculating all candidates when we have more than 1 jet passing our selection criteria. \n",
    "\n",
    "For MET, we make the assumption that the momentum vector represents a neutrino, and so has effectively 0 mass for our purposes. We are still making an incorrect assumption about $\\eta$, but this will work for our lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076a469-681b-4210-9066-93787cbe2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatjets = ak.zip(\n",
    "    {\"pt\": fatjet_pt[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "     \"eta\": fatjet_eta[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "     \"phi\": fatjet_phi[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "     \"mass\": fatjet_mass[cut_full_event][cut_fatjet[cut_full_event]]},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "\n",
    "muons = ak.zip(\n",
    "    {\"pt\": muon_pt[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"eta\": muon_eta[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"phi\": muon_phi[cut_full_event][cut_muon[cut_full_event]], \n",
    "     \"mass\": muon_mass[cut_full_event][cut_muon[cut_full_event]]},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "\n",
    "jets = ak.zip(\n",
    "    {\"pt\": jet_pt[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"eta\": jet_eta[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"phi\": jet_phi[cut_full_event][cut_jet[cut_full_event]], \n",
    "     \"mass\": jet_mass[cut_full_event][cut_jet[cut_full_event]]},\n",
    "    with_name=\"Momentum4D\",\n",
    ")\n",
    "\n",
    "met = ak.zip(\n",
    "    {\"pt\": met_pt[cut_full_event], \n",
    "     \"eta\": met_eta[cut_full_event], \n",
    "     \"phi\": met_phi[cut_full_event], \n",
    "     \"mass\": 0}, # We assume this is a neutrino with 0 mass\n",
    "    with_name=\"Momentum4D\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd594c3f-f35c-44e2-95b0-aec00c48acb5",
   "metadata": {},
   "source": [
    "We make use of some of the cool features of \n",
    "[Awkward to calculate the different combinations of particles](https://awkward-array.org/doc/main/getting-started/thinking-in-arrays.html).\n",
    "\n",
    "We can then use the python objects to calculate the sum of the 4-momentum of all our particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db980d3-e1da-490f-a9da-07154f670a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all the different combinations\n",
    "p4mu,p4fj,p4j,p4met = ak.unzip(ak.cartesian([muons, fatjets, jets, met]))\n",
    "\n",
    "# Calculate a sum of the 4-momenta\n",
    "p4tot = p4mu + p4fj + p4j + p4met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd48551-367e-4636-ac69-2c9ad14472c5",
   "metadata": {},
   "source": [
    "### **Challenge!**\n",
    "\n",
    "Now we can easily calculate the mass and make a quick and simple histogram, just to see if everything work. \n",
    "\n",
    "*Warning!* Make sure to `ak.flatten` your awkward array of masses before you pass the values to a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a9614-5ba2-41f3-ad61-5fb6e7d0eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mass\n",
    "x = p4tot.mass\n",
    "\n",
    "print(x)\n",
    "\n",
    "#ncand_cut = ak.num(x)==1\n",
    "ncand_cut = ak.num(x)>0\n",
    "\n",
    "# Plot it!\n",
    "# Your code here\n",
    "plt.figure()\n",
    "plt.hist(ak.flatten(x[ncand_cut]), bins=40, range=(0,4000));\n",
    "plt.hist(x[ncand_cut][:,0], bins=40, range=(0,4000));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc47a7-8177-4b9c-a4a4-4c78a46682b6",
   "metadata": {},
   "source": [
    "## Processing data files\n",
    "\n",
    "When we process the collision data, everything is going to be exactly the same, except that we need to select (mask)\n",
    "the data for which the beam luminosity was correctly calculated. \n",
    "\n",
    "This was explained in more detail in [previous lesson](https://cms-opendata-workshop.github.io/workshop2024-lesson-triggers-lumi/instructor/index.html) so we will just show you how to use it. \n",
    "\n",
    "We included a function to do this called `build_lumi_mask` and you imported it at the start of this notebook. It takes in the file (which we downloaded) that has the run information and the `events` `TTree` object. \n",
    "\n",
    "You can look at the JSON file if you like. This has the run info for the luminosity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b361a-84eb-4d95-9357-f17b84fea8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e4c87-d295-4059-8a12-bc991504cd19",
   "metadata": {},
   "source": [
    "Let's try this with a collisions file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cc001-0c4e-4702-a916-be65f46fb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = get_files_for_dataset(\"collision\", random=True, n=1)\n",
    "\n",
    "filename = filenames[0]\n",
    "\n",
    "print(f\"Opening...{filename}\")\n",
    "f = uproot.open(filename)\n",
    "\n",
    "events = f['Events']\n",
    "\n",
    "nevents = events.num_entries\n",
    "\n",
    "print(f\"{nevents = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdfa19-7b89-4073-8f73-2e0295bbc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_lumi = build_lumi_mask('Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt', events)\n",
    "\n",
    "print(mask_lumi)\n",
    "print(len(mask_lumi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c51f9b-dd2e-4baf-8d1f-ab7a195ed4ea",
   "metadata": {},
   "source": [
    "Note that the `mask_lumi` is an array of `True` and `False` for each event! So we can add this to our `cut_full_event`\n",
    "mask, *when we are processing collision data files*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd460f4-8be8-48ea-b508-c2cc77be438e",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "We've shown you all the building blocks to process both simulation and collision datasets. As you can see, in addition \n",
    "to processing the data, there is a lot of bookkeeping that has to be done in order to track datasets and files.\n",
    "\n",
    "*There is no single correct way to do this!* :)\n",
    "\n",
    "In fact, there are a number of different tools used by CMS experimentalists to do this, like [`coffea`](https://coffeateam.github.io/coffea/).\n",
    "\n",
    "Some of these hide away all of the extra bookkeeping but for purposes of our lesson, we will make it explicit. \n",
    "\n",
    "In the cell below we have taken all of the above code and put it inside a python function and taken out some of the comments, in the interest of brevity. \n",
    "\n",
    "The function takes as input\n",
    "* `filename`: the name of an input NanoAOD ROOT file\n",
    "* `dataset`:  string to be used to organize output files\n",
    "* `IS_DATA`: a flag that should be set to `True` if the input datafile is *collision* data.\n",
    "\n",
    "Again, there is no one right way to analyze all these datafiles but you will usually choose to write out a subset of the data for later analysis. You can do this in any format you like. We have chosen to write out `.csv` files, using the \n",
    "[`pandas` python library](https://pandas.pydata.org/) for ease of use. \n",
    "\n",
    "We are saving the following kinematic variables. \n",
    "\n",
    "* Mass of the $t\\overline{t}$ system\n",
    "* $p_T$ of the muon\n",
    "* $\\eta$ of the muon\n",
    "\n",
    "Those last two variables will be used to calculate uncertainties downstream in the analysis. \n",
    "\n",
    "There are also a few more variables that we are writing out, though we have not explained them yet. \n",
    "\n",
    "* `pileup`\n",
    "* `weight`\n",
    "* `nevents`\n",
    "* `N_gen`\n",
    "* `gw_pos`\n",
    "* `gw_neg`\n",
    "\n",
    "Let's give a very short explanation of each, but they will be discussed more in future lessons. \n",
    "\n",
    "`pileup` records how many proton-proton interactions were assumed when *simulated* data is processed. \n",
    "\n",
    "`weight` is the weight calculated by the Monte Carlo code used to simulate the interaction. It is often 1, but not always. This is a different value for each event. \n",
    "\n",
    "`nevents` is just the number of events in that file. We record the same number for each event in a file, just for ease of storage. \n",
    "\n",
    "`N_gen` is the difference of `gw_pos` and `gw_neg`. These are, respectively, the sum of the weights for all events that have `pos`itive values and the sum of the weights for all events that have `neg`ative values. For these values we again sum this up for all the events in a file and then store the same value for each event entry for ease of storage. \n",
    "\n",
    "These will be used to scale our simulation data accordingly when we compare with collision data and will be discussed in more detail in a future lesson. \n",
    "\n",
    "When we write out the `.csv` file, we name the file so that it contains the name of the input NanoAOD file and the dataset (e.g. `ttsemilep`) we are processing. \n",
    "\n",
    "The function returns a pandas dataframe, so you can play around with that, if you like. \n",
    "\n",
    "OK, let's process some files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedead8-2115-40ff-bb9b-5fc8fc2fe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, dataset='default', IS_DATA=False):\n",
    "    \n",
    "    print(f\"Opening...{filename}\")\n",
    "    \n",
    "    try:\n",
    "        f = uproot.open(filename)\n",
    "    except:\n",
    "        print(f\"Could not open {filename}\")\n",
    "        return None\n",
    "        \n",
    "    events = f['Events']\n",
    "\n",
    "    nevents = events.num_entries\n",
    "\n",
    "    print(f\"{nevents = }\")\n",
    "\n",
    "    # FatJet -----------------------------------------------------\n",
    "    fatjet_mSD = events['FatJet_msoftdrop'].array()\n",
    "\n",
    "    fatjet_tag = events['FatJet_particleNet_TvsQCD'].array()\n",
    "\n",
    "    fatjet_tau2 = events['FatJet_tau2'].array()\n",
    "    fatjet_tau3 = events['FatJet_tau3'].array()\n",
    "\n",
    "    fatjet_pt = events['FatJet_pt'].array()\n",
    "    fatjet_eta = events['FatJet_eta'].array()\n",
    "    fatjet_phi = events['FatJet_phi'].array()\n",
    "    fatjet_mass = events['FatJet_mass'].array()\n",
    "    \n",
    "    # Muons -------------------------------------------------------\n",
    "    muon_pt = events['Muon_pt'].array()\n",
    "    muon_eta = events['Muon_eta'].array()\n",
    "    muon_phi = events['Muon_phi'].array()\n",
    "    muon_mass = events['Muon_mass'].array()\n",
    "\n",
    "    muon_iso = events['Muon_miniIsoId'].array()\n",
    "\n",
    "    muon_tightId = events['Muon_tightId'].array()\n",
    "\n",
    "    \n",
    "    # Jets -------------------------------------------------------\n",
    "    jet_btag = events['Jet_btagDeepB'].array()\n",
    "    jet_jetid = events['Jet_jetId'].array()\n",
    "\n",
    "    jet_pt = events['Jet_pt'].array()\n",
    "    jet_eta = events['Jet_eta'].array()\n",
    "    jet_phi = events['Jet_phi'].array()\n",
    "    jet_mass = events['Jet_mass'].array()\n",
    "    \n",
    "    # MET ---------------------------------------------------------\n",
    "    met_pt = events['PuppiMET_pt'].array()\n",
    "    met_eta = 0*events['PuppiMET_pt'].array()  # Fix this to be 0\n",
    "    met_phi = events['PuppiMET_phi'].array() \n",
    "\n",
    "    ht_lep = muon_pt + met_pt\n",
    "    \n",
    "    #####################################################################################\n",
    "    # Cuts\n",
    "    #####################################################################################\n",
    "\n",
    "    # Particle-specific cuts --------------------------------------\n",
    "    tau32 = fatjet_tau3/fatjet_tau2\n",
    "\n",
    "    #cut_fatjet = (tau32>0.67) & (fatjet_eta>-2.4) & (fatjet_eta<2.4) & (fatjet_mSD>105) & (fatjet_mSD<220)\n",
    "    cut_fatjet = (fatjet_pt > 500) & (fatjet_tag > 0.5)\n",
    "\n",
    "    cut_muon = (muon_pt>55) & (muon_eta>-2.4) & (muon_eta<2.4) & \\\n",
    "               (muon_tightId == True) & (muon_iso>1) & (ht_lep>150)\n",
    "\n",
    "    cut_jet = (jet_btag > 0.5) & (jet_jetid>=4)\n",
    "\n",
    "\n",
    "\n",
    "    # Event cuts -------------------------------------------------\n",
    "    cut_met = (met_pt > 50)\n",
    "\n",
    "    cut_nmuons = ak.num(cut_muon[cut_muon]) == 1\n",
    "    cut_njets = ak.num(cut_jet[cut_jet]) == 1\n",
    "\n",
    "\n",
    "    cut_trigger = (events['HLT_TkMu50'].array())\n",
    "    \n",
    "    cut_ntop = ak.num(cut_fatjet[cut_fatjet]) == 1\n",
    "\n",
    "    cut_full_event = None\n",
    "    if IS_DATA:    \n",
    "        mask_lumi = build_lumi_mask('Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt', events)#, verbose=True)\n",
    "        cut_full_event = cut_trigger & cut_nmuons & cut_met & cut_ntop & mask_lumi\n",
    "    else:\n",
    "        cut_full_event = cut_trigger & cut_nmuons & cut_met & cut_ntop\n",
    "    \n",
    "    # Apply the cuts and calculate the di-top mass\n",
    "    fatjets = ak.zip(\n",
    "        {\"pt\": fatjet_pt[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "         \"eta\": fatjet_eta[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "         \"phi\": fatjet_phi[cut_full_event][cut_fatjet[cut_full_event]], \n",
    "         \"mass\": fatjet_mass[cut_full_event][cut_fatjet[cut_full_event]]},\n",
    "        with_name=\"Momentum4D\",\n",
    "    )\n",
    "\n",
    "    muons = ak.zip(\n",
    "        {\"pt\": muon_pt[cut_full_event][cut_muon[cut_full_event]], \n",
    "         \"eta\": muon_eta[cut_full_event][cut_muon[cut_full_event]], \n",
    "         \"phi\": muon_phi[cut_full_event][cut_muon[cut_full_event]], \n",
    "         \"mass\": muon_mass[cut_full_event][cut_muon[cut_full_event]]},\n",
    "        with_name=\"Momentum4D\",\n",
    "    )\n",
    "\n",
    "    jets = ak.zip(\n",
    "        {\"pt\": jet_pt[cut_full_event][cut_jet[cut_full_event]], \n",
    "         \"eta\": jet_eta[cut_full_event][cut_jet[cut_full_event]], \n",
    "         \"phi\": jet_phi[cut_full_event][cut_jet[cut_full_event]], \n",
    "         \"mass\": jet_mass[cut_full_event][cut_jet[cut_full_event]]},\n",
    "        with_name=\"Momentum4D\",\n",
    "    )\n",
    "\n",
    "    met = ak.zip(\n",
    "        {\"pt\": met_pt[cut_full_event], \n",
    "         \"eta\": met_eta[cut_full_event], \n",
    "         \"phi\": met_phi[cut_full_event], \n",
    "         \"mass\": 0}, # We assume this is a neutrino with 0 mass\n",
    "        with_name=\"Momentum4D\",\n",
    "    )\n",
    "    \n",
    "    p4mu,p4fj,p4j,p4met = ak.unzip(ak.cartesian([muons, fatjets, jets, met]))\n",
    "    \n",
    "    p4tot = p4mu + p4fj + p4j + p4met\n",
    "    \n",
    "    # Shape the weights and pileup\n",
    "    N_gen = -999\n",
    "    pileup = -999\n",
    "    gw_pos = -999\n",
    "    gw_neg = -999\n",
    "\n",
    "    pileup_per_candidate = None\n",
    "    \n",
    "    tmpval_events = np.ones(len(ak.flatten(p4tot.mass)))\n",
    "    tmpval = ak.ones_like(p4tot.mass)\n",
    "\n",
    "\n",
    "    # Put in the MC weights\n",
    "    if not IS_DATA:\n",
    "        gen_weights = events['genWeight'].array()[cut_full_event]\n",
    "        pileup = events['Pileup_nTrueInt'].array()[cut_full_event]\n",
    "\n",
    "        gen_weights_per_candidate = tmpval * gen_weights\n",
    "        #print(gen_weights_per_candidate)\n",
    "\n",
    "        pileup_per_candidate = tmpval * pileup\n",
    "        #print(pileup_per_candidate)\n",
    "\n",
    "        # Get values associated with the total number of events. \n",
    "        # It's going to duplicate the number of entries, but we'll save the same value to \n",
    "        # each event\n",
    "        gen_weights_org = events['genWeight'].array()\n",
    "\n",
    "        gw_pos = ak.count(gen_weights_org[gen_weights_org > 0])\n",
    "        gw_neg = ak.count(gen_weights_org[gen_weights_org < 0])\n",
    "        N_gen = gw_pos - gw_neg\n",
    "    else:\n",
    "        pileup_per_candidate = -999*tmpval\n",
    "        gen_weights_per_candidate = -999*tmpval\n",
    "    \n",
    "\n",
    "    # Build a dictionary and dataframe to write out the subset of data\n",
    "    # we are interested in\n",
    "    mydict = {}\n",
    "    mydict['mtt'] = ak.flatten(p4tot.mass) \n",
    "    mydict['mu_pt'] = ak.flatten(p4mu.pt) \n",
    "    mydict['mu_abseta'] = np.abs(ak.flatten(p4mu.eta))\n",
    "    mydict['pileup'] = ak.flatten(pileup_per_candidate)\n",
    "    mydict['weight'] = ak.flatten(gen_weights_per_candidate)\n",
    "    mydict['nevents'] = nevents*tmpval_events\n",
    "    mydict['N_gen'] = N_gen*tmpval_events\n",
    "    mydict['gw_pos'] = gw_pos*tmpval_events\n",
    "    mydict['gw_neg'] = gw_neg*tmpval_events\n",
    "\n",
    "    df = pd.DataFrame.from_dict(mydict)\n",
    "\n",
    "    outfilename = f\"OUTPUT_{dataset}_{filename.split('/')[-1].split('.')[0]}.csv\"\n",
    "    print(f'Saving output to {outfilename}')\n",
    "\n",
    "    df.to_csv(outfilename, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49874e2c-57a2-48f8-9556-b1e1ace5103c",
   "metadata": {},
   "source": [
    "Let's try using that function to process a couple of simulation files and a collision data file.\n",
    "\n",
    "Depending on the particular dataset you are looking at, the speed of your computer, and how many people are accessing the file,\n",
    "it may take between 20-90 seconds to process a single file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb1afe-94ec-4484-ab08-1130bfeb98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ttleptonic'\n",
    "\n",
    "filenames = get_files_for_dataset(dataset, random=True, n=1)\n",
    "filename = filenames[0]\n",
    "df = process_file(filename, dataset=dataset, IS_DATA=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd1b97-d974-4d20-80ba-b5c70847136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'collision'\n",
    "\n",
    "filenames = get_files_for_dataset(dataset, random=True, n=1)\n",
    "filename = filenames[0]\n",
    "\n",
    "# Don't forget to set IS_DATA to be true!\n",
    "df = process_file(filename, dataset=dataset, IS_DATA=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b5892-ba5b-401f-9e83-1689cc7967a9",
   "metadata": {},
   "source": [
    "Note that for the collision data, we don't store any information related to the weights or pileup, just the \n",
    "total number of events that was in the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5cb27-5f1a-43e4-a050-85e82204a659",
   "metadata": {},
   "source": [
    "Once you have a dataframe, you can make simple plots with it, just by pulling out the values from a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4d18c-3d41-4cca-b250-bded454dc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['mu_pt'].values\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(x,bins=50,range=(0,500))\n",
    "plt.xlabel(r'Muon $p_T$ [GeV/c]', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcff74a-f292-4298-8af3-d860c7f88b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of processing multiple files, each one writes out a separate .csv file\n",
    "\n",
    "dataset = 'tthadronic'\n",
    "\n",
    "# Get 3 files\n",
    "filenames = get_files_for_dataset(dataset, random=True, n=3)\n",
    "\n",
    "for filename in filenames:\n",
    "    df = process_file(filename, dataset=dataset, IS_DATA=False)\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1f03c-b6bc-4822-8890-4f2406f87089",
   "metadata": {},
   "source": [
    "We can list the contents of our directory to see the last few files we generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb176d-d09e-4b9d-8f7c-ebac2692e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98017f84-d4ec-417b-906d-5c88e620ef8c",
   "metadata": {},
   "source": [
    "And we can make sure there are entries in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6ae3b-0c3a-4140-ac85-3151e967e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 *tthadronic*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1e42e-44a5-414f-9dba-110dfcddae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec689f-acf8-4b3e-ae13-2ab2cf20c4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0766a8-774c-4927-814f-898db83fba71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
